{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zsVh5geCAfCE"
   },
   "source": [
    "## Step 1: Importing the necessary libaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 15036,
     "status": "ok",
     "timestamp": 1755465512525,
     "user": {
      "displayName": "Israr",
      "userId": "04789259546664681661"
     },
     "user_tz": -60
    },
    "id": "jYIM1lBooqLT",
    "outputId": "c1468af7-2bc2-43e3-a853-e49b4fe1faaa"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from google.colab import files\n",
    "from tensorflow.keras.utils import image_dataset_from_directory\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fIt1oXAJkk9K"
   },
   "source": [
    "## Step 2: Loading the Dataset into TensorFlow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7609,
     "status": "ok",
     "timestamp": 1755465565008,
     "user": {
      "displayName": "Israr",
      "userId": "04789259546664681661"
     },
     "user_tz": -60
    },
    "id": "Ea93ZYMck82s",
    "outputId": "2e1ac117-8651-4295-d021-3422b0a26ccc"
   },
   "outputs": [],
   "source": [
    "# PATH TO THE DATASET\n",
    "dataset_path = '/content/drive/MyDrive/Colab Notebooks/Research_Project/datasets/waste_dataset_v1'\n",
    "\n",
    "# TRAINING DATASET V1 (80% OF DATA)\n",
    "train_ds = image_dataset_from_directory(\n",
    "    dataset_path,\n",
    "    validation_split=0.2,\n",
    "    subset=\"training\",\n",
    "    seed=123,\n",
    "    image_size=(128, 128),\n",
    "    batch_size=32\n",
    ")\n",
    "\n",
    "# VALIDATION DATASET V1 (20% OF DATA)\n",
    "val_ds = image_dataset_from_directory(\n",
    "    dataset_path,\n",
    "    validation_split=0.2,\n",
    "    subset=\"validation\",\n",
    "    seed=123,\n",
    "    image_size=(128, 128),\n",
    "    batch_size=32\n",
    ")\n",
    "\n",
    "class_names = train_ds.class_names\n",
    "print(f\"Class Names: {class_names}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q64hrhzK4Re2"
   },
   "source": [
    "## Step 3: Visualizing the images\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 829
    },
    "executionInfo": {
     "elapsed": 8717,
     "status": "ok",
     "timestamp": 1755465576810,
     "user": {
      "displayName": "Israr",
      "userId": "04789259546664681661"
     },
     "user_tz": -60
    },
    "id": "XnNuvg7S4hSt",
    "outputId": "22ceda4a-31f4-4b3e-92e3-61f8aad4f1e2"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "for images, labels in train_ds.take(1):  # IT WILL TAKE ONE BATCH\n",
    "    for i in range(9):  # SHOW 9 IMAGES\n",
    "        plt.subplot(3, 3, i + 1)\n",
    "        plt.imshow(images[i].numpy().astype(\"uint8\"))  # CONVERT TO PROPER FORMAT\n",
    "        plt.title(class_names[labels[i]])  # ADD LABEL\n",
    "        plt.axis(\"off\")\n",
    "    break\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "15ElJRTf8zv3"
   },
   "source": [
    "## Step 4: Normalize the data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1755465576844,
     "user": {
      "displayName": "Israr",
      "userId": "04789259546664681661"
     },
     "user_tz": -60
    },
    "id": "u1vp1vwU8_W0"
   },
   "outputs": [],
   "source": [
    "train_ds = train_ds.map(lambda x, y: (x / 255.0, y)) \n",
    "val_ds = val_ds.map(lambda x, y: (x / 255.0, y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4Z9yEZ56GxSM"
   },
   "source": [
    "## Step 5: Building a CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 435
    },
    "executionInfo": {
     "elapsed": 460,
     "status": "ok",
     "timestamp": 1755465577316,
     "user": {
      "displayName": "Israr",
      "userId": "04789259546664681661"
     },
     "user_tz": -60
    },
    "id": "lOlOcd5HG4Dx",
    "outputId": "ad5e6e2a-b664-4ac5-92b7-cfeae7ec2f25"
   },
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(128, 128, 3)),  # CONVOLUTION LAYER\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),  # POOLING LAYER\n",
    "\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "\n",
    "    tf.keras.layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "\n",
    "    tf.keras.layers.Flatten(),  # CONVERT FEATURE MAPS TO 1D\n",
    "    tf.keras.layers.Dense(128, activation='relu'),  # FULLY CONNECTED LAYER\n",
    "    tf.keras.layers.Dense(len(class_names), activation='softmax')  # OUTPUT LAYER (SOFTMAX FOR MULTI-CLASS)\n",
    "])\n",
    "\n",
    "# COMPILE THE MODEL\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# DISPLAY THE MODEL SUMMARY\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eUlYEZc1R1sQ"
   },
   "source": [
    "## Step 6: Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 349
    },
    "executionInfo": {
     "elapsed": 451003,
     "status": "ok",
     "timestamp": 1755466037814,
     "user": {
      "displayName": "Israr",
      "userId": "04789259546664681661"
     },
     "user_tz": -60
    },
    "id": "wiPblQThR-co",
    "outputId": "aeae188e-27a6-43aa-d41b-fd8a48d3e677"
   },
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=9\n",
    ")\n",
    "\n",
    "model.save('/content/drive/MyDrive/<path for saving>/waste_classification_model_v1.keras')\n",
    "files.download('/content/drive/MyDrive/<path for saving>/waste_classification_model_v1.keras')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JBSsW8BEV7F0"
   },
   "source": [
    "## Step 7: Plotting Training Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 391
    },
    "executionInfo": {
     "elapsed": 465,
     "status": "ok",
     "timestamp": 1740256383250,
     "user": {
      "displayName": "Israr",
      "userId": "04789259546664681661"
     },
     "user_tz": 0
    },
    "id": "P9OQvk4rWEcp",
    "outputId": "235d537c-a584-4ca4-8ae1-290d8b378d6c"
   },
   "outputs": [],
   "source": [
    "# PLOT ACCURACY AND LOSS OVER EPOCHS\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "# ACCURACY PLOT\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Val Accuracy')\n",
    "plt.legend()\n",
    "plt.title(\"Accuracy over Epochs\")\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['loss'], label='Train Loss')\n",
    "plt.plot(history.history['val_loss'], label='Val Loss')\n",
    "plt.legend()\n",
    "plt.title(\"Loss over Epochs\")\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4Ug5SUhNWTFE"
   },
   "source": [
    "## Step 8: Test the Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 89,
     "status": "ok",
     "timestamp": 1739188451676,
     "user": {
      "displayName": "Israr",
      "userId": "04789259546664681661"
     },
     "user_tz": 0
    },
    "id": "oFNQ2T86WYE8",
    "outputId": "8066a525-12f5-4842-f196-b152c9e08e1c"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing import image\n",
    "import numpy as np\n",
    "\n",
    "# Load an image\n",
    "img_path = '/content/drive/MyDrive/Colab Notebooks/Research_Project/datasets/waste_dataset/glass/glass1.jpg'\n",
    "img = image.load_img(img_path, target_size=(128, 128))\n",
    "\n",
    "# Convert image to array and normalize\n",
    "img_array = np.expand_dims(np.array(img) / 255.0, axis=0)\n",
    "\n",
    "# Predict the class\n",
    "prediction = model.predict(img_array)\n",
    "predicted_class = class_names[np.argmax(prediction)]\n",
    "\n",
    "print(f\"Predicted Class: {predicted_class}\")\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyOqSRO8XqjIsV2IW2qpDZDh",
   "gpuType": "T4",
   "mount_file_id": "1YgcRFr7RiCwrCzDGhCrZXPxExVuFQ26m",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
